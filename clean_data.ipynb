{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10319, 40)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\naudio_hop_length = int((audio_data.shape[0] / sr) * sr / 63)\\nn_mfcc = 13\\n\\naudio_mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=n_mfcc, hop_length=audio_hop_length)\\n'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EMG Data Shape Info: Shape info: (10319,41)\n",
    "\"\"\" The EMG Data was measured at 2048 Hz, therefore with an estimated video length of 5 seconds, we would see roughly 10240 samples.\n",
    "    Therefore, we can safely assume that the data presented is the EMG Signals collected from 40 channels every 0.00048828125 seconds and an additional channel\n",
    "    pull high only at the start of each utterance\n",
    "\"\"\"\n",
    "emg_data = np.load('Spk1_Block1-Initial_0001_emg.npy')\n",
    "\"\"\"\n",
    "audio_file = 'Spk1_Block1-Initial_0001_audio.wav'\n",
    "sr = 16000\n",
    "audio_data, sr = librosa.load(audio_file, sr=sr)\n",
    "\"\"\"\n",
    "\n",
    "emg_signals = emg_data[:, :-1]\n",
    "print(emg_signals.shape)\n",
    "# This one signifies when a user speaks and doesn't\n",
    "marker_channel = emg_data[:, -1]\n",
    "print(marker_channel)\n",
    "window_size = 100\n",
    "hop_length = 55\n",
    "\"\"\"\n",
    "audio_hop_length = int((audio_data.shape[0] / sr) * sr / 63)\n",
    "n_mfcc = 13\n",
    "\n",
    "audio_mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=n_mfcc, hop_length=audio_hop_length)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 171, 2)\n"
     ]
    }
   ],
   "source": [
    "def extract_emg_features(emg_signal):\n",
    "  # Mean absolute value\n",
    "  mav = np.mean(np.abs(emg_signal))\n",
    "  # root mean square\\\n",
    "  rms = np.sqrt(np.mean(emg_signal ** 2))\n",
    "  return mav, rms\n",
    "\n",
    "emg_features = []\n",
    "\n",
    "# Process each channel\n",
    "for ch in range(emg_signals.shape[1]):\n",
    "  channel_features = []\n",
    "  for i in range(0, emg_signals.shape[0] - window_size, hop_length):\n",
    "    window = emg_signals[i:i + window_size, ch]\n",
    "    mav, rms = extract_emg_features(window) \n",
    "    channel_features.append([mav, rms])\n",
    "  emg_features.append(channel_features)\n",
    "\n",
    "emg_features = np.array(emg_features)\n",
    "print(emg_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate labels based on marker channel\n",
    "labels = []\n",
    "for i in range(0, marker_channel.shape[0] - window_size, hop_length):\n",
    "    window_marker = marker_channel[i:i + window_size]\n",
    "    label = 1 if np.mean(window_marker) > 0 else 0  # Threshold at 0\n",
    "    labels.append(label)\n",
    "labels = np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171,)\n",
      "(171, 80)\n"
     ]
    }
   ],
   "source": [
    "n_samples = emg_features.shape[1]\n",
    "emg_features_flat = emg_features.reshape(-1, emg_features.shape[2] * emg_features.shape[0])\n",
    "labels_flat = labels[:n_samples]  # Align labels with features\n",
    "print(labels_flat.shape)\n",
    "print (emg_features_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(emg_features_flat, labels_flat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           1       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        35\n",
      "   macro avg       0.96      0.62      0.68        35\n",
      "weighted avg       0.92      0.91      0.89        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train the classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
